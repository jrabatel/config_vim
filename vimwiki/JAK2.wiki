== Memory problem ==
* [ ] test with 1-level deep refining
  * [ ] measure memory consumption at the beginning and at the end of a refinement process
  * [ ] count the number of patterns generated
  * [ ] Is there a memory problem?
* [X] test with 2-level deep refining
  * [X] measure memory consumption at the beginning and at the end of a refinement process
  * [X] count the number of patterns generated
  * [ ] REMARK: the patterns do not seem to be deleted after the refinement process: memory consumption continually grows from a node to another
* [ ] How does the 2-step refiner work??
  * [ ] Why does the refinement operator return false several times for each node (2, 3 times)?
  * [ ] What is the refinerCallBack?
* [ ] What is PatternType for refiners?
* [ ] See jak2/decisionTree/refinementTestGenerator
  * [ ] generateRootNodeTestCollection
  * [ ] generateChildNodeTestCollection

== Pattern matcher ==
* [o] Optimizations based on multi-instance:
  * [ ] if preprocessing did not work because the domain of at least one vertex was empty, then do not test for other conformations of the same ligands. Note: this should work for vertex labels that are invariant wrt to the conformation (e.g., atom typing but not groundedAt).
  * [X] when the subgraph isomorphism test is false in a conformation, then we can order the vertices that "blocked" the test and test them first in the next conformations

== Input / Output ==
* [ ] Write input GraphViz method
* [ ] write down a file that can be read by Ronan

== Discretization ==
* [o] Propose an equal-width discretization for distances
  * [X] implementation of the discretizer
  * [X] in preprocessors and settings files, allow to change the distance discretizer type, as well as the number of overlapping intervals
  * [ ] integrate in the scripts
  * [ ] testing the different values
* [ ] Propose a variable discretization for coordinates
* [X] Allow overlapping intervals

== Experiments ==
* [ ] Allow a parallelization of experiments
  * [ ] separate the running of different DT learners on folds for one given experiment
  * [ ] Copy of the source code in one specific place (different from the one used to change the code)
  * [ ] a script to:
    * [ ] compile every required test
    * [ ] move it to a specific location (with folder name corresponding to the set of parameters)
  * [ ] a script to:
    * [ ] look for existing tests to run (look the corresponding folders)
    * [ ] if there is a test to run, move the corresponding folder to another place (currentlyRunningTasks)
    * [ ] run this test
* [ ] Datasets: find and study some datasets with 3D information
* [o] Cross-Validation:
  * [ ] check whether the segmentation proposed is good or not
    * [ ] variance in all obtained folds --> statistical test?
  * [X] write the obtained segmentation and use it for all the experiments
* [ ] Automatically create some plots to summarize the results
* [ ] Add a parameter about the post-pruning of the DT

== Decision Tree Learner ==
* [ ] Change the test selection criterion
  * [ ] use a non weighted version
  * [ ] find other measures

== Problems ==
* [ ] In the DT, the variance computation does not seem to be correct: leaves of size 1 have a non-0 variance value (positive or negative)
* [ ] Check the correctness of the DT tester: in a 1-fold cross-validation, test whether each conformation is associated to the correct leaf
* [ ] In ConjunctiveSubgraphIsomorphism, the distance-based options of conformations and atoms does not seem to be used
* [ ] The ROC-like measure scores are the same for every learned Decision Tree!!


== Scaffold Hopping context ==
* [ ] Problem definition

== General ideas ==
* [ ] Rely only on pharmacophores only (see the Scaffold Hopping paper for how to define them) to mine patterns (isn't it what they do in Muggleton 1998?)
* [ ] Try the DT learning process without hydrogen atoms
* [ ] Try to build a training dataset with a near miss principle (see Scaffold Hopping paper, Data preparation section)
* [ ] Use different ways of predicting values in a multi-conformation settings: the minimum IC50 value (used so far), the mean value, or others..
