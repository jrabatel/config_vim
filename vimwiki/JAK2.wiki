General ideas

Would it be possible to generate for each molecule a boolean vector of features, where each feature corresponds to a pattern used in a DT
In order to obtain several features, we can rely on the random forest learner.

Test association rules on fingerprinting vectors?
 -> could compress the vectors

Seminar of 

2012-10-02 Tue 08:38:26 CEST
Meeting Jak2
 - New data from Ronan, with two different docking tools
   - much larger amount of conformations per ligands (up to 700!)
   - first tests with 4-fold cross validation to compare performance with the old dataset, and the new ones
     - Results: slight improvement, but no complete datasets used (selection over the top generated conformations)

 - Virtual Screening
   - decoys
     - set of molecules that have different structure and similar chemical properties
     - often, the inactivity of decoys can only be assumed (because data are not available)
     - possible problems: when the decoys are too easy to distinguish from active compounds.
     - Benchmark datasets: ZINC, Directory of Useful Decoys DUD are already widely used
   - performance metrics
     - enrichment factor: intuitive and easy to interpret
       - ratio in the top X% of the ranked database, of the concentration of active ligands regarding the expected one
       - criticized because it strongly depends on the chosen X%
     - ROC and AUC, but does not take into account the early recognitin problem (best ligands should be at the top of the list)
     - Boltzmann-enhanced discrimination of the ROC (BedROC) metric, using an exponential wieghting to assign higher weights to early recognition
     - BedROC is a normalized version of the robust initial enhancement (RIE) measure

     - We already have a database of decoys provided by Ronan (is it still usable, compared to new data?)
     - First quick tests with weighted ROC

== Memory problem ==
* [ ] test with 1-level deep refining
  * [ ] measure memory consumption at the beginning and at the end of a refinement process
  * [ ] count the number of patterns generated
  * [ ] Is there a memory problem?
* [X] test with 2-level deep refining
  * [X] measure memory consumption at the beginning and at the end of a refinement process
  * [X] count the number of patterns generated
  * [ ] REMARK: the patterns do not seem to be deleted after the refinement process: memory consumption continually grows from a node to another
* [ ] How does the 2-step refiner work??
  * [ ] Why does the refinement operator return false several times for each node (2, 3 times)?
  * [ ] What is the refinerCallBack?
* [ ] What is PatternType for refiners?
* [ ] See jak2/decisionTree/refinementTestGenerator
  * [ ] generateRootNodeTestCollection
  * [ ] generateChildNodeTestCollection

== Pattern matcher ==
* [o] Optimizations based on multi-instance:
  * [ ] if preprocessing did not work because the domain of at least one vertex was empty, then do not test for other conformations of the same ligands. Note: this should work for vertex labels that are invariant wrt to the conformation (e.g., atom typing but not groundedAt).
  * [X] when the subgraph isomorphism test is false in a conformation, then we can order the vertices that "blocked" the test and test them first in the next conformations

== Input / Output ==
* [ ] Write input GraphViz method
* [ ] write down a file that can be read by Ronan

== Discretization ==
* [o] Propose an equal-width discretization for distances
  * [X] implementation of the discretizer
  * [X] in preprocessors and settings files, allow to change the distance discretizer type, as well as the number of overlapping intervals
  * [ ] integrate in the scripts
  * [ ] testing the different values
* [ ] Propose a variable discretization for coordinates
* [X] Allow overlapping intervals

== Experiments ==
* [ ] Allow a parallelization of experiments
  * [ ] separate the running of different DT learners on folds for one given experiment
  * [ ] Copy of the source code in one specific place (different from the one used to change the code)
  * [ ] a script to:
    * [ ] compile every required test
    * [ ] move it to a specific location (with folder name corresponding to the set of parameters)
  * [ ] a script to:
    * [ ] look for existing tests to run (look the corresponding folders)
    * [ ] if there is a test to run, move the corresponding folder to another place (currentlyRunningTasks)
    * [ ] run this test
* [ ] Datasets: find and study some datasets with 3D information
* [o] Cross-Validation:
  * [ ] check whether the segmentation proposed is good or not
    * [ ] variance in all obtained folds --> statistical test?
  * [X] write the obtained segmentation and use it for all the experiments
* [ ] Automatically create some plots to summarize the results
* [ ] Add a parameter about the post-pruning of the DT

== Decision Tree Learner ==
* [ ] Change the test selection criterion
  * [ ] use a non weighted version
  * [ ] find other measures

== Problems ==
* [ ] In the DT, the variance computation does not seem to be correct: leaves of size 1 have a non-0 variance value (positive or negative)
* [ ] Check the correctness of the DT tester: in a 1-fold cross-validation, test whether each conformation is associated to the correct leaf
* [ ] In ConjunctiveSubgraphIsomorphism, the distance-based options of conformations and atoms does not seem to be used
* [ ] The ROC-like measure scores are the same for every learned Decision Tree!!


== Scaffold Hopping context ==
* [ ] Problem definition

== General ideas ==
* [ ] Rely only on pharmacophores only (see the Scaffold Hopping paper for how to define them) to mine patterns (isn't it what they do in Muggleton 1998?)
* [ ] Try the DT learning process without hydrogen atoms
* [ ] Try to build a training dataset with a near miss principle (see Scaffold Hopping paper, Data preparation section)
* [ ] Use different ways of predicting values in a multi-conformation settings: the minimum IC50 value (used so far), the mean value, or others..
